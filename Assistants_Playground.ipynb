{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve an existing assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_QJm7WRrb9H9BDYnTYvvTigCJ', created_at=1701250340, description=None, file_ids=[], instructions='You are a Content Summarizer. You specialize in simplifying technical articles, video transcripts, documentations, papers, publications, etc. You break complex topics into to simple, manageable steps so non-technical people can understand. \\n\\nYou avoid any unnecessary jargon.\\n\\nYour content summaries are well structured and readable. ', metadata={}, model='gpt-4-1106-preview', name='Content Simplified', object='assistant', tools=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "content_assistant = client.beta.assistants.retrieve(\n",
    "    assistant_id=\"asst_QJm7WRrb9H9BDYnTYvvTigCJ\"\n",
    ")\n",
    "\n",
    "content_assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve an Existing Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thread(id='thread_9oHpvhFTZW3vkx0of4gQ6YBC', created_at=1701250662, metadata={}, object='thread')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_thread = client.beta.threads.retrieve(thread_id=\"thread_9oHpvhFTZW3vkx0of4gQ6YBC\")\n",
    "content_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get messages from the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_nUXxYx2Yg4uZIN5hIlcExPZx', assistant_id='asst_QJm7WRrb9H9BDYnTYvvTigCJ', content=[MessageContentText(text=Text(annotations=[], value='Here is a simplified, step-by-step educational guide based on the above Assistants API Beta documentation:\\n\\n### Step 1: Create an Assistant\\n- An assistant is an AI entity you configure to answer questions.\\n- It needs instructions (what to do) and a model (the AI brain).\\n- You can add tools like a Code Interpreter for the assistant to use.\\n- To create an assistant, you use code like this (you won\\'t actually write the code; this is just to show you what happens behind the scenes):\\n\\n```python\\nassistant = client.beta.assistants.create(\\n    name=\"Math Tutor\",\\n    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\\n    tools=[{\"type\": \"code_interpreter\"}],\\n    model=\"gpt-4-1106-preview\"\\n)\\n```\\nThis code creates a math tutor assistant.\\n\\n### Step 2: Create a Thread\\n- A thread is like a conversation room for one user.\\n- It starts when the user asks the first question.\\n- You can add as many messages as needed to this conversation.\\n- Creating the thread uses this sample code:\\n\\n```python\\nthread = client.beta.threads.create()\\n```\\n\\n### Step 3: Add a Message to a Thread\\n- A message is what the user or the assistant says in the conversation.\\n- You add the user\\'s questions or requests as messages in the thread.\\n- For example, a user might ask for help with a math problem:\\n\\n```python\\nmessage = client.beta.threads.messages.create(\\n    thread_id=thread.id,\\n    role=\"user\",\\n    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\\n)\\n```\\n\\n### Step 4: Run the Assistant\\n- To get an answer, you tell the assistant to look at the thread and respond.\\n- The assistant checks the conversation, uses its tools if needed, and replies.\\n- Here\\'s how a run could be initiated:\\n\\n```python\\nrun = client.beta.threads.runs.create(\\n  thread_id=thread.id,\\n  assistant_id=assistant.id,\\n  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\\n)\\n```\\nIn this step, you also can give specific instructions like how to address the user.\\n\\n### Step 5: Check the Run status\\n- A run starts in the \\'queued\\' state and then completes after a while.\\n- You can check whether the assistant has finished responding by checking the run\\'s status:\\n\\n```python\\nrun = client.beta.threads.runs.retrieve(\\n  thread_id=thread.id,\\n  run_id=run.id\\n)\\n```\\n\\n### Step 6: Display the Assistant\\'s Response\\n- Once the run is complete, the assistant\\'s messages are ready to show to the user.\\n- You collect the messages to see the assistant\\'s solution or answer:\\n\\n```python\\nmessages = client.beta.threads.messages.list(\\n  thread_id=thread.id\\n)\\n```\\n- Finally, you would show these messages to the user.\\n\\nIn the actual implementation, you will use OpenAI\\'s Python or Node.js SDKs which manage the technical details like HTTP headers automatically. This is a hands-off overview and the actual use requires some programming knowledge, or you can use the playground provided by OpenAI to experiment without coding.'), type='text')], created_at=1701250664, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_8hJsPRxPm9n2vlkb01Bm2nlv', thread_id='thread_9oHpvhFTZW3vkx0of4gQ6YBC'), ThreadMessage(id='msg_MqU3tMFWXCOKZiB1D514Av85', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Provide educational step by step guide based on this documentation:\\n<documentation>\\nAssistants API Beta\\nThe Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling. In the future, we plan to release more OpenAI-built tools, and allow you to provide your own tools on our platform.\\n\\nYou can explore the capabilities of the Assistants API using the Assistants playground or by building a step-by-step integration outlined in this guide. At a high level, a typical integration of the Assistants API has the following flow:\\n\\nCreate an Assistant in the API by defining its custom instructions and picking a model. If helpful, enable tools like Code Interpreter, Retrieval, and Function calling.\\nCreate a Thread when a user starts a conversation.\\nAdd Messages to the Thread as the user ask questions.\\nRun the Assistant on the Thread to trigger responses. This automatically calls the relevant tools.\\nThe Assistants API is in beta and we are actively working on adding more functionality. Share your feedback in our Developer Forum!\\nCalls to the Assistants API require that you pass a beta HTTP header. This is handled automatically if you’re using OpenAI’s official Python or Node.js SDKs.\\nOpenAI-Beta: assistants=v1\\nThis starter guide walks through the key steps to create and run an Assistant that uses Code Interpreter.\\n\\nAssistants playground\\nIn addition to the Assistants API, we also provide an Assistants playground (sign in required). The playground is a great way to explore the capabilities of the Assistants API and learn how to build your own Assistant without writing any code.\\n\\nStep 1: Create an Assistant\\nAn Assistant represents an entity that can be configured to respond to users’ Messages using several parameters like:\\n\\nInstructions: how the Assistant and model should behave or respond\\nModel: you can specify any GPT-3.5 or GPT-4 models, including fine-tuned models. The Retrieval tool requires gpt-3.5-turbo-1106 and gpt-4-1106-preview models.\\nTools: the API supports Code Interpreter and Retrieval that are built and hosted by OpenAI.\\nFunctions: the API allows you to define custom function signatures, with similar behavior as our function calling feature.\\nIn this example, we\\'re [creating an Assistant[(/docs/api-reference/assistants/createAssistant)] that is a personal math tutor, with the Code Interpreter tool enabled.\\n\\npython\\n\\npython\\nassistant = client.beta.assistants.create(\\n    name=\"Math Tutor\",\\n    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\\n    tools=[{\"type\": \"code_interpreter\"}],\\n    model=\"gpt-4-1106-preview\"\\n)\\nStep 2: Create a Thread\\nA Thread represents a conversation. We recommend creating one Thread per user as soon as the user initiates the conversation. Pass any user-specific context and files in this thread by creating Messages.\\n\\npython\\n\\npython\\nthread = client.beta.threads.create()\\nThreads don’t have a size limit. You can add as many Messages as you want to a Thread. The Assistant will ensure that requests to the model fit within the maximum context window, using relevant optimization techniques such as truncation which we have tested extensively with ChatGPT. When you use the Assistants API, you delegate control over how many input tokens are passed to the model for any given Run, this means you have less control over the cost of running your Assistant in some cases but do not have to deal with the complexity of managing the context window yourself.\\n\\nStep 3: Add a Message to a Thread\\nA Message contains text, and optionally any files that you allow the user to upload. Messages need to be added to a specific Thread. Adding images via message objects like in Chat Completions using GPT-4 with Vision is not supported today, but we plan to add support for them in the coming months. You can still upload images and have them processes via retrieval.\\n\\npython\\n\\npython\\nmessage = client.beta.threads.messages.create(\\n    thread_id=thread.id,\\n    role=\"user\",\\n    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\\n)\\nNow if you list the Messages in a Thread, you will see that this message has been appended.\\n\\n{\\n  \"object\": \"list\",\\n  \"data\": [\\n    {\\n      \"created_at\": 1696995451,\\n      \"id\": \"msg_abc123\",\\n      \"object\": \"thread.message\",\\n      \"thread_id\": \"thread_abc123\",\\n      \"role\": \"user\",\\n      \"content\": [{\\n        \"type\": \"text\",\\n        \"text\": {\\n          \"value\": \"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\\n          \"annotations\": []\\n        }\\n          }],\\n        ...\\nStep 4: Run the Assistant\\nFor the Assistant to respond to the user message, you need to create a Run. This makes the Assistant read the Thread and decide whether to call tools (if they are enabled) or simply use the model to best answer the query. As the run progresses, the assistant appends Messages to the thread with the role=\"assistant\". The Assistant will also automatically decide what previous Messages to include in the context window for the model. This has both an impact on pricing as well as model performance. The current approach has been optimized based on what we learned building ChatGPT and will likely evolve over time.\\n\\nYou can optionally pass additional instructions to the Assistant while creating the Run but note that these instructions override the default instructions of the Assistant.\\n\\npython\\n\\npython\\nrun = client.beta.threads.runs.create(\\n  thread_id=thread.id,\\n  assistant_id=assistant.id,\\n  instructions=\"Please address the user as Jane Doe. The user has a premium account.\"\\n)\\nStep 5: Check the Run status\\nBy default, a Run goes into the queued state. You can periodically retrieve the Run to check on its status to see if it has moved to completed.\\n\\npython\\n\\npython\\nrun = client.beta.threads.runs.retrieve(\\n  thread_id=thread.id,\\n  run_id=run.id\\n)\\nStep 6: Display the Assistant\\'s Response\\nOnce the Run completes, you can list the Messages added to the Thread by the Assistant.\\n\\npython\\n\\npython\\nmessages = client.beta.threads.messages.list(\\n  thread_id=thread.id\\n)\\nAnd finally, display them to the user! During this Run, the Assistant added two new Messages to the Thread. Here is an example of what that might look like:\\n\\nROLE\\tCONTENT\\nuser\\tI need to solve the equation 3x + 11 = 14. Can you help me?\\nassistant\\tCertainly, Jane Doe. To solve the equation (3x + 11 = 14) for (x), you\\'ll want to isolate (x) on one side of the equation. Here\\'s how you can do that:\\nSubtract 11 from both sides of the equation to get (3x = 3).\\nThen, divide both sides by 3 to solve for (x).\\nLet me calculate the value of (x) for you.\\nassistant\\tThe solution to the equation (3x + 11 = 14) is (x = 1).\\nYou can also retrieve the Run Steps of this Run if you\\'d like to explore or display the inner workings of the Assistant and its tools.\\n</documentation>'), type='text')], created_at=1701250662, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_9oHpvhFTZW3vkx0of4gQ6YBC')], object='list', first_id='msg_nUXxYx2Yg4uZIN5hIlcExPZx', last_id='msg_MqU3tMFWXCOKZiB1D514Av85', has_more=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_messages = client.beta.threads.messages.list(content_thread.id)\n",
    "content_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Provide educational step by step guide based on this documentation:\n",
      "<documentation>\n",
      "Assistants API B\n",
      "assistant: Here is a simplified, step-by-step educational guide based on the above Assistants API Beta document\n"
     ]
    }
   ],
   "source": [
    "for message in reversed(content_messages.data):\n",
    "    role = message.role\n",
    "    msg = message.content[0].text.value\n",
    "    print(f\"{role}: {msg[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new message to the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreadMessage(id='msg_o9WIB09EVETXxEjbGL43nNVr', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Create a more condense version of this summary. Solve the `5x + 10 = 35` equation.'), type='text')], created_at=1701251823, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_9oHpvhFTZW3vkx0of4gQ6YBC')\n"
     ]
    }
   ],
   "source": [
    "new_message = client.beta.threads.messages.create(\n",
    "  content_thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"Create a more condense version of this summary. Solve the `5x + 10 = 35` equation.\",\n",
    ")\n",
    "print(new_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the new message in the same thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_rfYiEVy0R80bX0ZvsxhKpm2W', assistant_id='asst_QJm7WRrb9H9BDYnTYvvTigCJ', cancelled_at=None, completed_at=None, created_at=1701251954, expires_at=1701252554, failed_at=None, file_ids=[], instructions='You are a Content Summarizer. You specialize in simplifying technical articles, video transcripts, documentations, papers, publications, etc. You break complex topics into to simple, manageable steps so non-technical people can understand. \\n\\nYou avoid any unnecessary jargon.\\n\\nYour content summaries are well structured and readable. ', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_9oHpvhFTZW3vkx0of4gQ6YBC', tools=[])\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=content_thread.id,\n",
    "  assistant_id=content_assistant.id\n",
    ")\n",
    "print(run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the run to check status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(id='run_rfYiEVy0R80bX0ZvsxhKpm2W', assistant_id='asst_QJm7WRrb9H9BDYnTYvvTigCJ', cancelled_at=None, completed_at=1701251970, created_at=1701251954, expires_at=None, failed_at=None, file_ids=[], instructions='You are a Content Summarizer. You specialize in simplifying technical articles, video transcripts, documentations, papers, publications, etc. You break complex topics into to simple, manageable steps so non-technical people can understand. \\n\\nYou avoid any unnecessary jargon.\\n\\nYour content summaries are well structured and readable. ', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=1701251954, status='completed', thread_id='thread_9oHpvhFTZW3vkx0of4gQ6YBC', tools=[])\n"
     ]
    }
   ],
   "source": [
    "new_run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=content_thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "print(new_run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Updated Messages in the Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_messages = client.beta.threads.messages.list(content_thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Provide educational step by step guide based on this documentation:\n",
      "<documentation>\n",
      "Assistants API B\n",
      "assistant: Here is a simplified, step-by-step educational guide based on the above Assistants API Beta document\n",
      "user: Create a more condense version of this summary. Solve the `5x + 10 = 35` equation.\n",
      "assistant: ### Condensed Guide to Using Assistants API Beta:\n",
      "\n",
      "1. **Create an Assistant**: Set up an AI entity w\n"
     ]
    }
   ],
   "source": [
    "for message in reversed(updated_messages.data):\n",
    "    role = message.role\n",
    "    msg = message.content[0].text.value\n",
    "    print(f\"{role}: {msg[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
